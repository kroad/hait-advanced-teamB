# -*- coding: utf-8 -*-
"""DL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oUj1v85UhF47jMUybYZffB8KkmiaTf85
"""

#パッケージのインストール
import numpy as np
import librosa
from tensorflow.keras.models import load_model
from PIL import Image
from tensorflow.keras.layers import Reshape
import pickle
import math

def predict(data_pass  : str):
  def get_mfcc(wav_path : str) -> np.ndarray:
    x, fs = librosa.load(wav_path, sr=44100)
    mfccs = librosa.feature.mfcc(x, sr=fs)
    mfccs = mfccs[1:]
    return mfccs

  MAX = 293.0886535644531
  MIN = -256.4121398925781
  def normalize(mfcc : np.ndarray) -> np.ndarray:
    return (mfcc - MIN)/(MAX - MIN)

  def resize(normalized_data : np.ndarray):
    imgdata = Image.fromarray(normalized_data)
    imgdata = imgdata.resize((512,19))
    imgdata = np.array(imgdata)
    imgdata = np.reshape(imgdata, (1, 19, 512))
    return imgdata
  
  def unpickle(file):
    # 保存されたpickleファイルを読み込み
    # 'rb'は｢読み込み専用(r)｣かつ｢バイト列(b)｣を意味する (binaryの略かもしれない)
    with open(file, 'rb') as f:
        return pickle.load(f, encoding='bytes')
  label_dict = unpickle('./label_dict_2.pkl')

  #modelのファイル名を入力
  #model_name = 'practice_0.h5'
  model = load_model('./practice_0.h5')

  #mfcc変換、標準化、サイズ変換
  mfcc_data = get_mfcc(data_pass)#仮　ここに音声データのパスを入れてください
  normalized_data = normalize(mfcc_data)
  resized_data = resize(normalized_data)

  #予測
  out = model.predict(resized_data)
  
  #辞書を作る
  return_data = {}
  for i in np.argsort(-(out.flatten()))[:5]:
    for k, v in label_dict.items():
      if v == i:
        return_data[k] = math.floor(out.flatten()[i] * 100)
  
  return return_data