# -*- coding: utf-8 -*-
"""pytorch_predict.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1i0JpfSiqxe0UeaHVzf4f2LvhdBZOWJy4
"""

# PyTorch ver.

from torchvision import models, transforms
import numpy as np
from PIL import Image
import cv2, librosa, os
import torch.nn as nn
import torch

def predict(data_path: str):

    label_dict = {
        'ASIAN KUNG-FU GENERATION': 42,
        "B'z": 0,
        'BOOWY': 43,
        'BUMP OF CHICKEN': 7,
        'Billy Joel': 2,
        'DREAMS COME TRUE': 10,
        'ELLEGARDEN': 9,
        'Every Little Thing': 11,
        'GLAY': 44,
        'KANA-BOON': 12,
        "L'Arc~en~Ciel": 52,
        'LiSA': 13,
        'MISIA': 50,
        'Mr.Children': 14,
        'Mrs.GREEN APPLE': 15,
        'ONE OK ROCK': 18,
        'Oasis': 16,
        'Official髭男dism': 17,
        'RADWINPS': 19,
        'SEKAI NOOWARI': 20,
        'Superfly': 22,
        'T.M.Revolution': 23,
        'UNISON SQUARE GARDEN': 24,
        'YUI': 5,
        '[Alexandros]': 6,
        'aiko': 4,
        'back number': 8,
        'miwa': 49,
        'sumika': 21,
        'あいみょん': 25,
        'クリープハイプ': 26,
        'ゲスの極み乙女。': 3,
        'サザンオールスターズ': 27,
        'サンボマスター': 45,
        'スピッツ': 28,
        'チャットモンチー': 29,
        'ポルノグラフィティ': 1,
        'マカロニえんぴつ': 31,
        '中島 美嘉': 48,
        '宇多田ヒカル': 30,
        '安室奈美恵': 46,
        '平井堅': 38,
        '德永英明': 41,
        '松任谷由実': 33,
        '松田聖子': 47,
        '椎名林檎': 36,
        '槇原敬之': 40,
        '水樹奈々': 34,
        '浜崎あゆみ': 37,
        '福山雅治': 51,
        '米津玄師': 39,
        '銀杏BOYZ': 32,
        '長渕剛': 35}

    size = (224, 224)
    mean = (0.485, 0.456, 0.406)
    std = (0.229, 0.224, 0.225)

    def get_tensor(img, resize, mean, std):
        tfms = transforms.Compose([
            transforms.Resize(resize),
            transforms.ToTensor(),
            transforms.Normalize(mean, std)
            ])
        return torch.unsqueeze(tfms(img), 0) #次元を追加

# 学習済みのVGG-16モデルをロード

# VGG-16モデルのインスタンスを生成
    net = models.vgg16()

# VGG16の最後の出力層の出力ユニットをアーティスト数に置き換える
    net.classifier[6] = nn.Linear(in_features=4096, out_features=len(label_dict))

#print('ネットワーク設定完了：学習済みの重みをロードし、訓練モードに設定しました')

# PyTorchのネットワークパラメータのロード
    load_path = '/home/tamahassam/Desktop/hait-advanced-teamB/apiv1/machine_learning/weights_fine_tuning_1_0.pth'

    load_weights = torch.load(load_path, map_location={'cuda:0': 'cpu'})
    net.load_state_dict(load_weights)
    net = net.eval()

    maximum = 230
    minimum = -180

    def normalize(ndarray):
        ndarray = np.clip(ndarray, minimum, maximum)
        return (ndarray - minimum)/(maximum - minimum)

    def get_mfcc(wav_path: str) -> np.ndarray:
        x, fs = librosa.load(wav_path, sr=44100)
        mfccs = librosa.feature.mfcc(x, sr=fs)
        mfccs = mfccs[1:]
        return mfccs

    #img_path = '/content/drive/MyDrive/test/菅田将暉.wav'
    _img = get_mfcc(data_path)
    _img_normalized = (normalize(_img) * 255).astype(np.uint8)
    img_color = cv2.applyColorMap(_img_normalized, cv2.COLORMAP_JET)
    img = Image.fromarray(img_color)

    out = net(get_tensor(img, size, mean, std))

    out_np = out.detach().numpy()
#print(type(out_np))


#out_np_ = np.round(out_np, decimals=3)

# リストを作る
    result = []
    for i in np.argsort(-(out_np.flatten()))[:5]:
        for k, v in label_dict.items():
            if v == i:
                result.append({"artist": k, "prob": "{:.3f} %".format(out_np.flatten()[i])})
#result
    return result